# IPL-Data-Analysis-End-To-End-Apache-Spark-Databricks-Project
In this project, I have executed an End-To-End Data Engineering Project i.e., IPL Data Analysis using Apache Spark and Databricks. This project performs large-scale analysis of IPL cricket match data using PySpark.
The goal is to derive insights such as venue-wise scoring patterns, player performance and match trends.

## Architecture Diagram

![Architecture Diagram](images/architecture.jpg)


## Technology Used
- Programming Language - Python & PySpark
- AWS S3 (Data Source)
  
1. PySpark & Spark SQL (Transformation logic)
2. Apache Spark Basics and Databricks
3. Pandas (For Data Cleaning)
4. Matplotlib & Seaborn (Visualizing data for insights)
- Apache Spark

## Key Analysis
- Average and highest scores by venue
- Player-wise performance analysis
- Match-level aggregations
- Data quality handling and transformations

## How to Run
1. Upload the data to S3
2. Configure Spark session
3. Run the scripts

## Learnings
- Optimized Spark SQL queries
- Handling large datasets efficiently
- Spark â†’ Pandas visualization workflow
- Data engineering best practices

## Future Improvements
- Add Delta Lake support
- Implement data quality checks
- Add Airflow orchestration

## Dataset Used
Here is the dataset used in the project - https://data.world/login?next=%2Fraghu543%2Fipl-data-till-2017
